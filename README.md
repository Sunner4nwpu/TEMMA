
This repository contains the code for TEMMA.

## Citing & Authors
if you find this repository helpful, please cite our publication:

## Citation
```
@ARTICLE{9257201,
author={H. {Chen} and D. {Jiang} and H. {Sahli}},
journal={IEEE Transactions on Multimedia},
title={Transformer Encoder with Multi-modal Multi-head Attention for Continuous Affect Recognition},
year={2020},
doi={10.1109/TMM.2020.3037496}}
```

Contact person: Haifeng Chen,  Email: Sunner4nwpu@163.com


## Acknowledgement
* The codes of basemodel_1D is borrowed from [TCN](https://github.com/locuslab/TCN).
* The structure of the codebase is borrowed from [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
